{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px backgound =;'> Análise e Classificação de Faces: Visão Computacional com OpenCV </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 01 - Conhecendo o problema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Preparando Ambiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bibliotecas instaladas\n",
    "\n",
    "conda install -c conda-forge opencv=3.4.3\n",
    "\n",
    "conda install jupyter\n",
    "\n",
    "conda install -c conda-forge dlib\n",
    "\n",
    "conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7180/2056285236.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib  \n",
    "import seaborn \n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Abrindo uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrindo uma imagem (open cv abre as imagens BGR)\n",
    "\n",
    "imagem = cv2.imread(\"imagens/px-girl.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando a imagem \n",
    "\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando as cores não são importantes, convertemos as imagens para escala cinza para facilitar a análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo as cores imagem para de BGR para RGB\n",
    "\n",
    "imagem_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando a imagem\n",
    "plt.imshow(imagem_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 canais\n",
    "imagem_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo a imagem para cinza\n",
    "imagem_gray = cv2.cvtColor(imagem_rgb, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando a imagem \n",
    "plt.imshow(imagem_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Definindo uma região de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo imagem\n",
    "imagem = cv2.imread(\"imagens/px-peaple.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo imagem para rgb\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando recorte da imagem \n",
    "imagem_roi = imagem[100:200, 1000:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando recorte\n",
    "plt.imshow(imagem_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"imagem_roi.png\", imagem_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_roi_bgr = cv2.cvtColor(imagem_roi, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(\"imagem_roi.png\", imagem_roi_bgr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02- Segmentaão de faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Classificador de cascata de Haar(Selecionando o rosto de forma automatica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2236/1155041038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimagem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"imagens/px-people.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "imagem = cv2.imread(\"imagens/px-people.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convesão RGB\n",
    "\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo para cinza\n",
    "\n",
    "imagem_gray = cv2.cvtColor(imagem, vc2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = cv2.CascadeClassifier(\"classificadores/haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ª parametro se refere a escala 1.3\n",
    "2º parametro\n",
    "\n",
    "Estamos reduzindo a imagem a uma taxa de 30%, quantos mais rostos a ser identificado, menor deve ser a porcetagem para ser melhor a resolução do programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = classificador.detectMultiScale(imagem_gray, 1.3, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2236/1146226140.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#retorna quantos rostos foi identificado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "#retorna quantos rostos foi identificado\n",
    "len(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Trabalhando regiões de interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando a 1 face \n",
    "faces[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "Cordenadas de como posso fazer um retangulo em volta de uma face\n",
    "</br>\n",
    "2 numeros a esquerda se refere ao x, y</br>\n",
    "2 numeros a direitas altura e compimento\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando uma copia da imagem\n",
    "\n",
    "imagem_anotada = imagem.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(imagem_anotada, (x,y), (x+w, y+h), (255,255,0),2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize)\n",
    "plt.imshow(imagem_anotada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recortando as faces e armazenado cada uma encontrada\n",
    "\n",
    "face_imagem = 0\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    face_imagem +- 1\n",
    "    imagem_roi = imagem[y:y+h, +x:x+w]                       #recortando \n",
    "    imagem_roi = cv2.cvtColor(imagem_roi, cv2.COLOR_RGB2BGR) #convertendo \n",
    "    vc2.imwrite(\"face_\" + str(face_imagem) + \".png\", imagem_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 - Classificação de faces (identificar quem é a pessoa da imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2-Separação de imagens(15 imagens por pessoa, já cortadas somente as faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir, path, makedirs\n",
    "from os.path import isfile, join\n",
    "\n",
    "import shutil\n",
    "\n",
    "from sklearn.metrics import acuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizar os arquivos \"3 imagens/''\n",
    "\n",
    "imagem_face_1 = cv2.imread(\"imagens/cropped_faces/s01_01.jpg\")\n",
    "imagem_face_1 = cv2.cvtColor(imagem_face_1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "imagem_face_2 = cv2.imread(\"imagens/cropped_faces/s02_01.jpg\")\n",
    "imagem_face_2 = cv2.cvtColor(imagem_face_2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "imagem_face_3 = cv2.imread(\"imagens/cropped_faces/s03_01.jpg\")\n",
    "imagem_face_3 = cv2.cvtColor(imagem_face_3, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Sujeito 01\")\n",
    "plt.imshow(imagem_face_1)\n",
    "plt.subplot(132)\n",
    "plt.title(\"Sujeito 02\")\n",
    "plt.imshow(imagem_face_2)\n",
    "plt.subplot(133)\n",
    "plt.title(\"Sujeito 03\")\n",
    "plt.imshow(imagem_face_3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_face_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_face_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_face_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram separadas 15 imagens, 10 imagens teinos 5 para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2236/1546902815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Comando para redimensionar essas imagens para tamanho comum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfaces_caminho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"imagens/cropped_faces/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlista_arq_faces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces_caminho\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces_caminho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "#Comando para redimensionar todas imagens nesse diretório para tamanho comum\n",
    "\n",
    "faces_caminho = \"imagens/cropped_faces/\"\n",
    "lista_arq_faces = [f for f in listdir(faces_caminho) if isfile (join(faces_caminho, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arq_faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_arq_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_path_treino = \"imagens/treino/\"\n",
    "faces_path_teste = \"imagens/teste/\"\n",
    "\n",
    "if not path.exists(faces_path_treino):\n",
    "    makedirs(faces_path_treino)\n",
    "\n",
    "if not path.exists(faces_path_teste):\n",
    "    makedirs(faces_path_teste)\n",
    "\n",
    "for arq in lista_arq_faces:\n",
    "    sujeito = arq[1:3]\n",
    "    numero = arq[4:6]\n",
    "    \n",
    "    if int(numero) <= 10:\n",
    "        shutil.copyfile(faces_caminho + arq, faces_path_treino + arq)\n",
    "    else:\n",
    "        shutil.copyfile(faces_caminho + arq, faces_path_teste + arq)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Padronização de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padronizar_imagem(imagem_caminho):\n",
    "    imagem = cv2.imread(imagem_caminho, cv2.IMREAD_GRAYSCALE)\n",
    "    imagem = cv2.resize(imagem, (200, 200), interpolation=cv2.INTER_LANCZOS4)\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando imagem por imagem para dentro da função padronizar_imagem\n",
    "lista_faces_treino = [f for f in listdir(faces_path_treino) if isfile(join(faces_path_treino, f))]\n",
    "lista_faces_teste = [f for f in listdir(faces_path_teste) if isfile(join(faces_path_teste, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_faces_treino[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_faces_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento, sujeitos = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados Treino\n",
    "for i, arq in enumerate(lista_faces_treino):\n",
    "    imagem_path = faces_path_treino + arq\n",
    "    imagem = padronizar_imagem(imagem_path)\n",
    "    dados_treinamento.append(imagem)\n",
    "    sujeito = arq[1:3]\n",
    "    sujeitos.append(int(sujeito))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dados_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sujeitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste, sujeitos_teste = [], [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados teste\n",
    "for i, arq in enumerate(lista_faces_teste):\n",
    "    imagem_path = faces_path_teste + arq\n",
    "    imagem = padronizar_imagem(imagem_path)\n",
    "    dados_teste.append(imagem)\n",
    "    sujeito = arq[1:3]\n",
    "    sujeitos_teste.append(int(sujeito))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sujeitos_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dados_treinamento[0], cmap=\"gray\")\n",
    "plt.title(sujeito[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dados_teste[0], cmap=\"gray\")\n",
    "plt.title(sujeitos_teste[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 -Algoritmos de Classificação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2- Classificador Eingenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dados_teste[0], cmap=\"gray\")\n",
    "plt.title(sujeitos_teste[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujeitos = np.asarray(sujeitos, dtype=np.int32)\n",
    "sujeitos_teste = np.asarray(sujeitos_teste, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_eingenfaces = cv2.face.EigenFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_eingenfaces.train(dados_treinamento, sujeitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[6]))\n",
    "plt.imshow(dados_teste[6], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[7]))\n",
    "plt.imshow(dados_teste[7], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_eingenfaces.predict(dados_teste[6])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_eingenfaces.predict(dados_teste[7])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_fisherfaces = cv2.face.FisherFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_fisherfaces.train(dados_treinamento, sujeitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[13]))\n",
    "plt.imshow(dados_teste[13], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[19]))\n",
    "plt.imshow(dados_teste[19], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_eingenfaces.predict(dados_teste[6])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_eingenfaces.predict(dados_teste[7])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 - Classificador Fisherfaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_fisherfaces = cv2.face.FisherFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_fisherfaces.train(dados_treinamento, sujeitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[13]))\n",
    "plt.imshow(dados_teste[13], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[19]))\n",
    "plt.imshow(dados_teste[19], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_fisherfaces.predict(dados_teste[13])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_fisherfaces.predict(dados_teste[19])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 - Classificador LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lbph = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lbph.train(dados_treinamento, sujeitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[21]))\n",
    "plt.imshow(dados_teste[21], cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Sujeito \" + str(sujeitos_teste[27]))\n",
    "plt.imshow(dados_teste[27], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_lbph.predict(dados_teste[21])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = modelo_lbph.predict(dados_teste[27])\n",
    "predicao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 - Precisão dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eingenfaces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dados_teste:\n",
    "    y_pred_eingenfaces.append(modelo_eingenfaces.predict(item)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_eingenfaces = accuracy_score(sujeitos_teste, y_pred_eingenfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_eingenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fisherfaces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dados_teste:\n",
    "    y_pred_fisherfaces.append(modelo_fisherfaces.predict(item)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_fisherfaces = accuracy_score(sujeitos_teste, y_pred_fisherfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_fisherfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lbph = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in dados_teste:\n",
    "    y_pred_lbph.append(modelo_lbph.predict(item)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_lbph = accuracy_score(sujeitos_teste, y_pred_lbph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_lbph"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8050f0f7b036217db9f353e540e6033101148f2e2dd24c9ad6f2b82034d5875c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
